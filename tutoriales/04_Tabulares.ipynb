{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score,balanced_accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from plotly import express as px\n",
    "\n",
    "#from UA_MDM_LDI_II.tutoriales.utils import plot_confusion_matrix\n",
    "from utils import plot_confusion_matrix\n",
    "\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.artifacts import FileSystemArtifactStore, upload_artifact\n",
    "\n",
    "from joblib import load, dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = './'\n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train/train.csv\")\n",
    "PATH_TO_MODELS = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/models\")\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/optuna_temp_artifacts\")\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/optuna_artifacts\")\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 50\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos Tabulares\n",
    "dataset = pd.read_csv(PATH_TO_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset,\n",
    "                               test_size = TEST_SIZE,\n",
    "                               random_state = SEED,\n",
    "                               stratify = dataset.AdoptionSpeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_feats = [f for f in dataset.columns if dataset[f].dtype=='O']\n",
    "numeric_feats = [f for f in dataset.columns if dataset[f].dtype!='O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Type',\n",
    " 'Age',\n",
    " 'Breed1',\n",
    " 'Breed2',\n",
    " 'Gender',\n",
    " 'Color1',\n",
    " 'Color2',\n",
    " 'Color3',\n",
    " 'MaturitySize',\n",
    " 'FurLength',\n",
    " 'Vaccinated',\n",
    " 'Dewormed',\n",
    " 'Sterilized',\n",
    " 'Health',\n",
    " 'Quantity',\n",
    " 'Fee',\n",
    " 'State',\n",
    " 'VideoAmt',\n",
    " 'PhotoAmt']\n",
    "\n",
    "label = 'AdoptionSpeed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[label]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = params = {\n",
    "                        'objective': 'multiclass',\n",
    "                        'num_class': len(y_train.unique())\n",
    "                        }\n",
    "\n",
    "\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train)\n",
    "\n",
    "\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                      lgb_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "cohen_kappa_score(y_test,y_pred, weights = 'quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plot_confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(y_test,y_test, weights = 'quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plot_confusion_matrix(y_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_shuffled = shuffle(y_test,\n",
    "                     random_state = 42)\n",
    "\n",
    "\n",
    "dict_map_cerca = {0:1,\n",
    "                  1:2,\n",
    "                  2:3,\n",
    "                  3:4,\n",
    "                  4:3}\n",
    "\n",
    "dict_map_lejos = {0:4,\n",
    "                  1:4,\n",
    "                  2:0,\n",
    "                  3:0,\n",
    "                  4:0}\n",
    "\n",
    "y_cerca = [dict_map_cerca[i] for i in y_test]\n",
    "\n",
    "y_lejos = [dict_map_lejos[i] for i in y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_list =  np.random.rand(len(y_test))\n",
    "\n",
    "kappa_progression = pd.DataFrame()\n",
    "\n",
    "for i in range(101):\n",
    "\n",
    "    y_simulado = [y_test.iloc[sample] if random_list[sample]<i/100 else y_shuffled.iloc[sample] for sample in range(len(y_test))]\n",
    "\n",
    "    y_simulado_cerca = [y_test.iloc[sample] if random_list[sample]<i/100 else y_cerca[sample] for sample in range(len(y_test))]\n",
    "\n",
    "    y_simulado_lejos = [y_test.iloc[sample] if random_list[sample]<i/100 else y_lejos[sample] for sample in range(len(y_test))]\n",
    "\n",
    "\n",
    "    kappa_progression = pd.concat([kappa_progression,\n",
    "                                   pd.DataFrame({'Conocidos':[i],\n",
    "                                                'kappa':cohen_kappa_score(y_test,\n",
    "                                                                        y_simulado,\n",
    "                                                                        weights = 'quadratic'),\n",
    "                                                'kappa_cerca':cohen_kappa_score(y_test,\n",
    "                                                                        y_simulado_cerca,\n",
    "                                                                        weights = 'quadratic'),\n",
    "                                                'kappa_lejos':cohen_kappa_score(y_test,\n",
    "                                                                        y_simulado_lejos,\n",
    "                                                                        weights = 'quadratic'),                                                                        \n",
    "                                                'accuracy':accuracy_score(y_test,\n",
    "                                                                        y_simulado),\n",
    "                                                'balanced_accuracy':balanced_accuracy_score(y_test,\n",
    "                                                                        y_simulado),\n",
    "                                                                        })],\n",
    "                ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(kappa_progression,x='Conocidos',y=['kappa',\n",
    "                                           'kappa_cerca',\n",
    "                                           'kappa_lejos',\n",
    "                                           'accuracy',\n",
    "                                           'balanced_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_simulado_cerca = [y_test.iloc[sample] if random_list[sample]<50/100 else y_cerca[sample] for sample in range(len(y_test))]\n",
    "\n",
    "display(plot_confusion_matrix(y_test,y_simulado_cerca, \n",
    "                              title = \"Kappa \" + str(cohen_kappa_score(y_test,y_simulado_cerca, weights = 'quadratic'))))\n",
    "\n",
    "\n",
    "y_simulado_lejos = [y_test.iloc[sample] if random_list[sample]<50/100 else y_lejos[sample] for sample in range(len(y_test))]\n",
    "\n",
    "display(plot_confusion_matrix(y_test,y_simulado_lejos, \n",
    "                              title = \"Kappa \" + str(cohen_kappa_score(y_test,y_simulado_lejos, weights = 'quadratic'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = params = {\n",
    "                        'objective': 'multiclassova',\n",
    "                        'num_class': len(y_train.unique())\n",
    "                        }\n",
    "\n",
    "\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train)\n",
    "\n",
    "\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                      lgb_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = lgb_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "display(plot_confusion_matrix(y_test,y_pred))\n",
    "\n",
    "{'kappa':cohen_kappa_score(y_test,\n",
    "                y_pred,\n",
    "                weights = 'quadratic'),\n",
    " 'accuracy':accuracy_score(y_test,y_pred),\n",
    " 'balanced_accuracy':balanced_accuracy_score(y_test,y_pred)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    lgb_params = {      \n",
    "                        'objective': 'multiclass',\n",
    "                        'verbosity':-1,\n",
    "                        'num_class': len(y_train.unique()),\n",
    "                        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "                        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "                        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "                        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "                        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                        } \n",
    "\n",
    "\n",
    "    lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                    label=y_train)\n",
    "\n",
    "\n",
    "    lgb_model = lgb.train(lgb_params,\n",
    "                        lgb_train_dataset)\n",
    "    \n",
    "    return(cohen_kappa_score(y_test,lgb_model.predict(X_test).argmax(axis=1),\n",
    "                             weights = 'quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"04 - LGB Multiclass\",\n",
    "                            load_if_exists=True)\n",
    "study.optimize(lgb_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params =  {      \n",
    "                        'objective': 'multiclass',\n",
    "                        'verbosity':-1,\n",
    "                        'num_class': len(y_train.unique())} | study.best_params\n",
    "\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train)\n",
    "\n",
    "\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                    lgb_train_dataset)\n",
    "\n",
    "display(plot_confusion_matrix(y_test,lgb_model.predict(X_test).argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_custom_metric_kappa(dy_pred, dy_true):\n",
    "\n",
    "    metric_name = 'kappa'\n",
    "    value = cohen_kappa_score(dy_true.get_label(),dy_pred.argmax(axis=1),weights = 'quadratic')\n",
    "    is_higher_better = True\n",
    "    return(metric_name, value, is_higher_better)\n",
    "\n",
    "def cv_es_lgb_objective(trial):\n",
    "\n",
    "    lgb_params = {      \n",
    "                        'objective': 'multiclass',\n",
    "                        'verbosity':-1,\n",
    "                        'num_class': len(y_train.unique()),\n",
    "                        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "                        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "                        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "                        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "                        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                        } \n",
    "\n",
    "    scores_ensemble = np.zeros((len(y_test),len(y_train.unique())))\n",
    "    score_folds = 0\n",
    "    n_splits = 5\n",
    "\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    for i, (if_index, oof_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        \n",
    "        lgb_if_dataset = lgb.Dataset(data=X_train.iloc[if_index],\n",
    "                                        label=y_train.iloc[if_index],\n",
    "                                        free_raw_data=False)\n",
    "        \n",
    "        lgb_oof_dataset = lgb.Dataset(data=X_train.iloc[oof_index],\n",
    "                                        label=y_train.iloc[oof_index],\n",
    "                                        free_raw_data=False)\n",
    "\n",
    "        lgb_model = lgb.train(lgb_params,\n",
    "                                lgb_if_dataset,\n",
    "                                valid_sets=lgb_oof_dataset,\n",
    "                                callbacks=[lgb.early_stopping(10, verbose=False)],\n",
    "                                feval = lgb_custom_metric_kappa\n",
    "                                )\n",
    "        \n",
    "        scores_ensemble = scores_ensemble + lgb_model.predict(X_test) #prediction!!!!\n",
    "        \n",
    "        score_folds = score_folds + cohen_kappa_score(y_train.iloc[oof_index], \n",
    "                                                            lgb_model.predict(X_train.iloc[oof_index]).argmax(axis=1),weights = 'quadratic')/n_splits\n",
    "\n",
    "\n",
    "    predicted_filename = os.path.join(PATH_TO_TEMP_FILES,f'test_{trial.study.study_name}_{trial.number}.joblib')\n",
    "    predicted_df = test.copy()\n",
    "    predicted_df['pred'] = [scores_ensemble[p,:] for p in range(scores_ensemble.shape[0])]\n",
    "    dump(predicted_df, predicted_filename)\n",
    "    upload_artifact(trial, predicted_filename, artifact_store)    \n",
    "\n",
    "    cm_filename = os.path.join(PATH_TO_TEMP_FILES,f'cm_{trial.study.study_name}_{trial.number}.jpg')\n",
    "    plot_confusion_matrix(y_test,scores_ensemble.argmax(axis=1)).write_image(cm_filename)\n",
    "    upload_artifact(trial, cm_filename, artifact_store)\n",
    "\n",
    "    test_score = cohen_kappa_score(y_test,scores_ensemble.argmax(axis=1),weights = 'quadratic')\n",
    "    trial.set_user_attr(\"test_score\", test_score)\n",
    "\n",
    "    return(score_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n",
    "\n",
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"04 - LGB Multiclass CV\",\n",
    "                            load_if_exists = True)\n",
    "\n",
    "study.optimize(cv_es_lgb_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
